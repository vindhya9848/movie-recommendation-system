{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61697253",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: sentence-transformers in c:\\users\\vindhya lingareddy\\appdata\\roaming\\python\\python39\\site-packages (5.1.2)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\vindhya lingareddy\\appdata\\roaming\\python\\python39\\site-packages (1.6.1)\n",
      "Requirement already satisfied: pandas in c:\\users\\vindhya lingareddy\\appdata\\roaming\\python\\python39\\site-packages (2.3.1)\n",
      "Requirement already satisfied: scipy in c:\\users\\vindhya lingareddy\\appdata\\roaming\\python\\python39\\site-packages (from sentence-transformers) (1.13.1)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in c:\\users\\vindhya lingareddy\\appdata\\roaming\\python\\python39\\site-packages (from sentence-transformers) (4.57.3)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in c:\\users\\vindhya lingareddy\\appdata\\roaming\\python\\python39\\site-packages (from sentence-transformers) (0.36.0)\n",
      "Requirement already satisfied: Pillow in c:\\users\\vindhya lingareddy\\appdata\\roaming\\python\\python39\\site-packages (from sentence-transformers) (11.3.0)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in c:\\users\\vindhya lingareddy\\appdata\\roaming\\python\\python39\\site-packages (from sentence-transformers) (4.14.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\vindhya lingareddy\\appdata\\roaming\\python\\python39\\site-packages (from sentence-transformers) (4.67.1)\n",
      "Requirement already satisfied: torch>=1.11.0 in c:\\users\\vindhya lingareddy\\appdata\\roaming\\python\\python39\\site-packages (from sentence-transformers) (2.8.0)\n",
      "Requirement already satisfied: numpy>=1.19.5 in c:\\users\\vindhya lingareddy\\appdata\\roaming\\python\\python39\\site-packages (from scikit-learn) (2.0.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\vindhya lingareddy\\appdata\\roaming\\python\\python39\\site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\vindhya lingareddy\\appdata\\roaming\\python\\python39\\site-packages (from scikit-learn) (1.5.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\vindhya lingareddy\\appdata\\roaming\\python\\python39\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\vindhya lingareddy\\appdata\\roaming\\python\\python39\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\vindhya lingareddy\\appdata\\roaming\\python\\python39\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\vindhya lingareddy\\appdata\\roaming\\python\\python39\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.5.1)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\vindhya lingareddy\\appdata\\roaming\\python\\python39\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\vindhya lingareddy\\appdata\\roaming\\python\\python39\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.2)\n",
      "Requirement already satisfied: requests in c:\\users\\vindhya lingareddy\\appdata\\roaming\\python\\python39\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.3)\n",
      "Requirement already satisfied: filelock in c:\\users\\vindhya lingareddy\\appdata\\roaming\\python\\python39\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.19.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\vindhya lingareddy\\appdata\\roaming\\python\\python39\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\vindhya lingareddy\\appdata\\roaming\\python\\python39\\site-packages (from torch>=1.11.0->sentence-transformers) (1.14.0)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\vindhya lingareddy\\appdata\\roaming\\python\\python39\\site-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
      "Requirement already satisfied: networkx in c:\\users\\vindhya lingareddy\\appdata\\roaming\\python\\python39\\site-packages (from torch>=1.11.0->sentence-transformers) (3.2.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\vindhya lingareddy\\appdata\\roaming\\python\\python39\\site-packages (from tqdm->sentence-transformers) (0.4.6)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\vindhya lingareddy\\appdata\\roaming\\python\\python39\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2025.11.3)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\vindhya lingareddy\\appdata\\roaming\\python\\python39\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.7.0)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in c:\\users\\vindhya lingareddy\\appdata\\roaming\\python\\python39\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.22.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\vindhya lingareddy\\appdata\\roaming\\python\\python39\\site-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\vindhya lingareddy\\appdata\\roaming\\python\\python39\\site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\vindhya lingareddy\\appdata\\roaming\\python\\python39\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.4.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\vindhya lingareddy\\appdata\\roaming\\python\\python39\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2025.4.26)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\vindhya lingareddy\\appdata\\roaming\\python\\python39\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\vindhya lingareddy\\appdata\\roaming\\python\\python39\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.10)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 22.0.4; however, version 25.3 is available.\n",
      "You should consider upgrading via the 'C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Python39_64\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "#%pip install sentence-transformers scikit-learn pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d395dd0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From d:\\movie-recommendation-system\\.venv\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "Loading dataset...\n",
      "Dataset Loaded:\n",
      "                                                text  label\n",
      "0                            i didnt feel humiliated      0\n",
      "1  i can go from feeling so hopeless to so damned...      0\n",
      "2   im grabbing a minute to post i feel greedy wrong      3\n",
      "3  i am ever feeling nostalgic about the fireplac...      2\n",
      "4                               i am feeling grouchy      3\n",
      "\n",
      "Loading SentenceTransformer model...\n",
      "Encoding text into embeddings...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.calibration import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "\n",
    "print(\"Loading dataset...\")\n",
    "\n",
    "df = pd.read_csv(\"datasets/mood-data.csv\") \n",
    "df = df[['text', 'label']] \n",
    "\n",
    "\n",
    "print(\"Dataset Loaded:\")\n",
    "print(df.head())\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 2. Convert labels to integers (if needed)\n",
    "# ---------------------------------------------------------\n",
    "\n",
    "# If labels already 0–4, no need to encode, but let's be safe:\n",
    "label_encoder = LabelEncoder()\n",
    "df['label'] = label_encoder.fit_transform(df['label'])\n",
    "\n",
    "label_names = {0: \"sadness\", 1: \"joy\", 2: \"love\", 3: \"anger\", 4: \"fear\", 5:\"surprise\"}\n",
    "\n",
    "df['label_name'] = df['label'].map(label_names)\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df[\"text\"], \n",
    "    df[\"label\"], \n",
    "    test_size=0.2, \n",
    "    random_state=42,\n",
    "    stratify=df[\"label\"]\n",
    ")\n",
    "\n",
    "print(\"\\nLoading SentenceTransformer model...\")\n",
    "embedder = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "print(\"Encoding text into embeddings...\")\n",
    "X_train_emb = embedder.encode(X_train.tolist(), batch_size=32, convert_to_numpy=True)\n",
    "X_test_emb = embedder.encode(X_test.tolist(), batch_size=32, convert_to_numpy=True)\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_emb)\n",
    "X_test_scaled = scaler.transform(X_test_emb)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a662775f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">98,560</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">774</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │        \u001b[38;5;34m98,560\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m32,896\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m)              │           \u001b[38;5;34m774\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">132,230</span> (516.52 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m132,230\u001b[0m (516.52 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">132,230</span> (516.52 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m132,230\u001b[0m (516.52 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "model = models.Sequential([\n",
    "    layers.Input(shape=(384,)),           # embedding size of MiniLM\n",
    "    layers.Dense(256, activation=\"relu\"),\n",
    "    layers.Dropout(0.3),\n",
    "    layers.Dense(128, activation=\"relu\"),\n",
    "    layers.Dropout(0.3),\n",
    "    layers.Dense(6, activation=\"softmax\")  # 6 emotion labels\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3e9b4243",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.5554 - loss: 1.2176 - val_accuracy: 0.6695 - val_loss: 0.9239\n",
      "Epoch 2/20\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6711 - loss: 0.9048 - val_accuracy: 0.6906 - val_loss: 0.8379\n",
      "Epoch 3/20\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7061 - loss: 0.7863 - val_accuracy: 0.6836 - val_loss: 0.8121\n",
      "Epoch 4/20\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7408 - loss: 0.7053 - val_accuracy: 0.7148 - val_loss: 0.7795\n",
      "Epoch 5/20\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7607 - loss: 0.6350 - val_accuracy: 0.7125 - val_loss: 0.7944\n",
      "Epoch 6/20\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7829 - loss: 0.5840 - val_accuracy: 0.7055 - val_loss: 0.7866\n",
      "Epoch 7/20\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8010 - loss: 0.5262 - val_accuracy: 0.7188 - val_loss: 0.7672\n",
      "Epoch 8/20\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8156 - loss: 0.4929 - val_accuracy: 0.7094 - val_loss: 0.7964\n",
      "Epoch 9/20\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8246 - loss: 0.4618 - val_accuracy: 0.7219 - val_loss: 0.7763\n",
      "Epoch 10/20\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8424 - loss: 0.4200 - val_accuracy: 0.7125 - val_loss: 0.8006\n",
      "Epoch 11/20\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8504 - loss: 0.3987 - val_accuracy: 0.7070 - val_loss: 0.8009\n",
      "Epoch 12/20\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8635 - loss: 0.3667 - val_accuracy: 0.7172 - val_loss: 0.8388\n",
      "Epoch 13/20\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8654 - loss: 0.3478 - val_accuracy: 0.7250 - val_loss: 0.8297\n",
      "Epoch 14/20\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8773 - loss: 0.3248 - val_accuracy: 0.7180 - val_loss: 0.8552\n",
      "Epoch 15/20\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8844 - loss: 0.3073 - val_accuracy: 0.7281 - val_loss: 0.8816\n",
      "Epoch 16/20\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8943 - loss: 0.2861 - val_accuracy: 0.7219 - val_loss: 0.9161\n",
      "Epoch 17/20\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8970 - loss: 0.2714 - val_accuracy: 0.7203 - val_loss: 0.9373\n",
      "Epoch 18/20\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9033 - loss: 0.2600 - val_accuracy: 0.7156 - val_loss: 0.9565\n",
      "Epoch 19/20\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9060 - loss: 0.2546 - val_accuracy: 0.7219 - val_loss: 0.9800\n",
      "Epoch 20/20\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9109 - loss: 0.2428 - val_accuracy: 0.7281 - val_loss: 0.9793\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    X_train_scaled,\n",
    "    y_train,\n",
    "    validation_split=0.1,\n",
    "    epochs=20,\n",
    "    batch_size=64,\n",
    "    verbose=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1d846fa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Accuracy: 0.725625\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.81      0.78       933\n",
      "           1       0.73      0.83      0.78      1072\n",
      "           2       0.59      0.41      0.48       261\n",
      "           3       0.75      0.64      0.69       432\n",
      "           4       0.69      0.64      0.66       387\n",
      "           5       0.65      0.40      0.49       115\n",
      "\n",
      "    accuracy                           0.73      3200\n",
      "   macro avg       0.69      0.62      0.65      3200\n",
      "weighted avg       0.72      0.73      0.72      3200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test_scaled)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_classes))\n",
    "print(classification_report(y_test, y_pred_classes))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5544f154",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "940dc133",
   "metadata": {},
   "source": [
    "### Selected Project Track: Content Recommendation System\n",
    "## Problem Statement: \n",
    "Most of the recommendation systems offer movies based on user's watch history, this novel movie bot recommends content based on user's current mood, because: sometimes user feels like watching movie according to their mood or movies similar to the plot they liked before, rather than just based on the past watch history.\n",
    "\n",
    "This movie bot can be trained on the movies database for a specific OTT platorms like: Netflix or Prime Video and this movie bot can be added as a layer on top of the Netflix or OTT platform's UI and fetch movies according to user's mood and other preferences, This model can further be extended to collect additional information like: user's tastes type of movie they might like and so on"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5178c338",
   "metadata": {},
   "source": [
    "## This project is a movie assistant that recommends movies based on:\n",
    "\n",
    "user's mood-> predicts genres he might like -> asks language preference-> asks similar movies he might like -> prinnts top 5 movies\n",
    "\n",
    "## The project consists of step by step approach:\n",
    "1. *Dataset preparation:* extraction Pre-processing (I used TMDB dataset for movies metadata: https://www.themoviedb.org/)\n",
    "2. *Creating Vector embeddings:* I used FAISS in memory vector DB to embed movies dataset\n",
    "3. *LLMs - Integrated Gemini API* to process few ambigous user inputs (like mood prediction, extracting similar movie description)\n",
    "4. *Create reranker model* to sort the recommendations based on semantic similarity\n",
    "5. *Recommendation Module->* module that takes user preferences and matches with movie's metadata to display top 5 movies\n",
    "6. *Converstation Manager Module* -> To manage questions to be ased and processes user inputs by storing user preferences in a state Class\n",
    "7. *Chatbot Service Module*- used as an orchestrator for Chatbot simulation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "251f942b",
   "metadata": {},
   "source": [
    "### 1 Data Preparation: I extracted data using TMDB API Keys \n",
    "\n",
    "-> Dataset present in datasets/raw \n",
    "-> after cleansing will load data to datasets/cleaned which has cleaned formatted fields with no null values and additional column added: 'embedding_text' which is embedded using sentence-transformer model in FAISS vector DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "31069f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f32d7b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../datasets/raw/movies_raw.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7a39ff9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "movie_id               int64\n",
      "title                 object\n",
      "overview              object\n",
      "genres                object\n",
      "cast                  object\n",
      "keywords              object\n",
      "runtime                int64\n",
      "release_year           int64\n",
      "language              object\n",
      "vote_average         float64\n",
      "vote_count             int64\n",
      "combined_features     object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4fb9e8a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "movie_id               0\n",
      "title                  0\n",
      "overview             219\n",
      "genres                 0\n",
      "cast                   0\n",
      "keywords               0\n",
      "runtime                0\n",
      "release_year           0\n",
      "language               0\n",
      "vote_average           0\n",
      "vote_count             0\n",
      "combined_features      0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "05e0a54b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.fillna({'overview': 'no overview'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e49df365",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "# this method handles text cleaning: since some lists are of type string\n",
    "\n",
    "def normalize_text(x):\n",
    "    # Handle NaN\n",
    "    if pd.isna(x):\n",
    "        return \"\"\n",
    "\n",
    "    # Case 1: already a real list\n",
    "    if isinstance(x, list):\n",
    "        return \", \".join(g.strip() for g in x if isinstance(g, str) and g.strip())\n",
    "\n",
    "    # Case 2: string that looks like a list -> parse it\n",
    "    if isinstance(x, str):\n",
    "        x = x.strip()\n",
    "\n",
    "        # empty or invalid\n",
    "        if x.lower() in [\"\", \"nan\", \"none\", \"[]\"]:\n",
    "            return \"\"\n",
    "\n",
    "        # stringified list like \"['Drama', 'Romance']\"\n",
    "        if x.startswith(\"[\") and x.endswith(\"]\"):\n",
    "            try:\n",
    "                parsed = ast.literal_eval(x)\n",
    "                if isinstance(parsed, list):\n",
    "                    return \", \".join(\n",
    "                        g.strip() for g in parsed if isinstance(g, str) and g.strip()\n",
    "                    )\n",
    "            except Exception:\n",
    "                pass  # fall through\n",
    "\n",
    "        # already pipe or comma separated\n",
    "        return x.replace(\",\", \", \")\n",
    "\n",
    "    return \"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "55ffd5be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "# removes brackets and single quotes from string: []'\n",
    "def clean_brackets(text):\n",
    "    if pd.isna(text):\n",
    "        return \"\"\n",
    "    # Remove [, ], and ' using regex\n",
    "    return re.sub(r\"[\\[\\]']\", \"\", str(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "447f13b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "def clean_text(text):\n",
    "    if pd.isna(text):\n",
    "        return \"\"\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"[^a-z\\s,:.\\'\\\"]\", \"\", text)\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f5d7ca16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "67    bruce gets phone calls from a woman claiming t...\n",
       "68    a part original movie featuring scorpio: an ag...\n",
       "69    abel is a ghostwriter. he just finished writin...\n",
       "70    many years after a deadly terrorist siege in a...\n",
       "71    filmed version of the stratford festival produ...\n",
       "72    following a brutal civil war, an interrogation...\n",
       "73    tunein on friday midnight to watch relaxing ol...\n",
       "74                                          no overview\n",
       "Name: overview, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['overview']= df['overview'].apply(clean_text)\n",
    "df['overview'].iloc[67:75]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e3b10e99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "df['keywords'] = df['keywords'].apply(normalize_text).apply(clean_brackets)\n",
    "\n",
    "df['keywords'].tail(5)\n",
    "\n",
    "df[\"genres\"] = df[\"genres\"].apply(normalize_text).apply(lambda x: x.lower())\n",
    "\n",
    "df[\"genres\"].head(2)\n",
    "\n",
    "df['genres']= df['genres'].apply(clean_brackets)\n",
    "df[\"keywords\"].iloc[87:94]\n",
    "df['cast']=df['cast'].apply(normalize_text)\n",
    "\n",
    "df['cast']= df['cast'].apply(clean_brackets)\n",
    "\n",
    "df['runtime'] = df['runtime'].astype(int)\n",
    "df['release_year']=df['release_year'].astype(int)\n",
    "\n",
    "# Check if the keywords at index 87 is empty (length 0)\n",
    "print(type(df['overview'].iloc[87]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "05c1ed50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pycountry\n",
    "import pandas as pd\n",
    "# helper method to convert iso codes of language to full language: ex: 'en' is converted to 'english'\n",
    "def convert_lang(code):\n",
    "    if pd.isnull(code):\n",
    "        return code\n",
    "    \n",
    "    # pycountry needs uppercase 2-letter codes (e.g., 'EN')\n",
    "    code_clean = str(code).strip().upper()\n",
    "    \n",
    "    try:\n",
    "        lang = pycountry.languages.get(alpha_2=code_clean)\n",
    "        return lang.name.lower() if lang else code\n",
    "    except (AttributeError, LookupError):\n",
    "        return code\n",
    "\n",
    "# Apply the helper function\n",
    "df[\"language\"] = df[\"language\"].apply(convert_lang)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "958cc12c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'english'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['language']= df['language'].apply(lambda x: x.lower() if isinstance(x,str) else x)\n",
    "df['language'].iloc[78]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f1495cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_with_keywords(row):\n",
    "    \"\"\"\n",
    "    Takes a row (Series) from the DataFrame.\n",
    "    If overview is 'no overview', joins keywords into a string.\n",
    "    this method replaces empty overview with keywords\n",
    "    \"\"\"\n",
    "    # Access columns by name from the row object\n",
    "    overview = str(row['overview']).lower().strip()\n",
    "    keywords = row['keywords']\n",
    "    genres = str(row['genres'])\n",
    "    \n",
    "    # Logic: if 'no overview' and keywords exist\n",
    "    if overview == 'no overview' and len(keywords) > 0:\n",
    "        # If keywords is a list, join it; if it's already a string, return it\n",
    "        if isinstance(keywords, str):\n",
    "            row['extracted_text'] = str(keywords.strip())\n",
    "        return row\n",
    "    \n",
    "    if overview == 'no overview' and len(genres) > 0:\n",
    "        if isinstance(genres, str):\n",
    "            row['extracted_text'] = str(genres.strip())\n",
    "        return row\n",
    "\n",
    "    row['extracted_text'] = pd.NA\n",
    "    # Otherwise, keep the original overview\n",
    "    return row\n",
    "\n",
    "df = df.apply(replace_with_keywords, axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8ea739ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22                          france, society, confinement\n",
       "74     sports, basketball, national basketball associ...\n",
       "98                                       comedy, romance\n",
       "119                                   documentary, music\n",
       "120    archive footage, movie star, hollywood star, g...\n",
       "Name: extracted_text, dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask = (df['extracted_text'].notna())\n",
    "\n",
    "df.loc[mask, 'extracted_text'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d9452517",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "movie_id             170\n",
      "title                170\n",
      "overview             170\n",
      "genres               170\n",
      "cast                 170\n",
      "keywords             170\n",
      "runtime              170\n",
      "release_year         170\n",
      "language             170\n",
      "vote_average         170\n",
      "vote_count           170\n",
      "combined_features    170\n",
      "extracted_text       170\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Creates a view of the data where extracted_text has values\n",
    "filtered_df = df[df['extracted_text'].notna()]\n",
    "print(filtered_df.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bf9d28a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from thefuzz import fuzz, process\n",
    "# helper method to get unique keywords, so that vector embedding does not contain noise\n",
    "def get_unique_fuzzy_keywords(input_str, threshold=70):\n",
    "    # 1. Clean and split the string into a list\n",
    "    raw_keywords = [k.strip() for k in input_str.split(',') if k.strip()]\n",
    "    raw_keywords.sort(key= len, reverse= True)\n",
    "    \n",
    "    unique_keywords = []\n",
    "\n",
    "    for kw in raw_keywords:\n",
    "        # 2. Check if the keyword is similar to anything already accepted\n",
    "        # If the list is empty, just add the first word\n",
    "        if not unique_keywords:\n",
    "            unique_keywords.append(kw)\n",
    "            continue\n",
    "        \n",
    "        # 3. Find the best match score among already accepted words\n",
    "        # extractOne returns (best_match, score)\n",
    "        _, score = process.extractOne(kw, unique_keywords, scorer=fuzz.token_set_ratio)\n",
    "        \n",
    "        # 4. If the similarity score is low, it's a \"unique\" new concept\n",
    "        if score < threshold:\n",
    "            unique_keywords.append(kw)\n",
    "            \n",
    "    return unique_keywords\n",
    "\n",
    "# Example Usage\n",
    "# data = \"sports, basketball, national basketball association (nba)\"\n",
    "# result = get_unique_fuzzy_keywords(data)\n",
    "\n",
    "# print(result) \n",
    "# Output: ['sports', 'national basketball association (nba)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2e1227d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = (df['extracted_text'].notna())\n",
    "\n",
    "df.loc[mask,'extracted_text']= df.loc[mask,'extracted_text'].apply(get_unique_fuzzy_keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "57282866",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22                        [confinement, society, france]\n",
       "74       [national basketball association (nba), sports]\n",
       "98                                     [romance, comedy]\n",
       "119                                 [documentary, music]\n",
       "120    [biographical documentary, archive footage, li...\n",
       "Name: extracted_text, dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[mask,'extracted_text'].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0faada99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22     a movie that is about: confinement,society,france\n",
       "74     a movie that is about: national basketball ass...\n",
       "98                 a movie that is about: romance,comedy\n",
       "119             a movie that is about: documentary,music\n",
       "120    a movie that is about: biographical documentar...\n",
       "Name: extracted_text, dtype: object"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def keywords_to_plot(keywords: list):\n",
    "    if isinstance(keywords,list):\n",
    "        keyword_text = ','.join(keywords)\n",
    "        text_to_append = 'a movie that is about: '\n",
    "        \n",
    "        final_text = text_to_append + keyword_text\n",
    "        return final_text\n",
    "    \n",
    "\n",
    "df.loc[mask,'extracted_text']= df.loc[mask,'extracted_text'].apply(keywords_to_plot)\n",
    "\n",
    "df.loc[mask,'extracted_text'].head(5)\n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "283aabc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def new_overview(row):\n",
    "    overview = row['overview']\n",
    "    extracted_text = row['extracted_text']\n",
    "    keywords = row['keywords']\n",
    "\n",
    "    # Use pd.isna() instead of 'is pd.nan'\n",
    "    if overview == 'no overview':\n",
    "        if not pd.isna(extracted_text):\n",
    "            row['new_overview'] = extracted_text\n",
    "        else:\n",
    "            row['new_overview'] = 'no overview'\n",
    "    else:\n",
    "        if isinstance(keywords,str) and len(keywords):\n",
    "            row['new_overview'] = overview+' '+keywords\n",
    "        else:\n",
    "            row['new_overview']= overview\n",
    "\n",
    "        \n",
    "\n",
    "    return row\n",
    "\n",
    "# Specify axis=1 to process by row\n",
    "df = df.apply(new_overview, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "50c600a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "movie_id             49\n",
       "title                49\n",
       "overview             49\n",
       "genres               49\n",
       "cast                 49\n",
       "keywords             49\n",
       "runtime              49\n",
       "release_year         49\n",
       "language             49\n",
       "vote_average         49\n",
       "vote_count           49\n",
       "combined_features    49\n",
       "extracted_text        0\n",
       "new_overview         49\n",
       "dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['new_overview']=='no overview'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "34fcf56f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select all rows where the condition is False \n",
    "# removing rows that neither have keywords, genres or overview since they don't add any values to embeddings\n",
    "df = df[~(df['new_overview'] == 'no overview')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "48ac74c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "movie_id             4951\n",
       "title                4951\n",
       "overview             4951\n",
       "genres               4951\n",
       "cast                 4951\n",
       "keywords             4951\n",
       "runtime              4951\n",
       "release_year         4951\n",
       "language             4951\n",
       "vote_average         4951\n",
       "vote_count           4951\n",
       "combined_features    4951\n",
       "extracted_text        170\n",
       "new_overview         4951\n",
       "dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4b9adfe2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['movie_id', 'title', 'overview', 'genres', 'cast', 'keywords',\n",
       "       'runtime', 'release_year', 'language', 'vote_average', 'vote_count',\n",
       "       'combined_features', 'extracted_text', 'new_overview'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d8509f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_keep = [\n",
    "    'movie_id', 'title', 'genres', 'cast', 'keywords', \n",
    "    'runtime', 'release_year', 'language', \n",
    "    'vote_average', 'vote_count', 'new_overview'\n",
    "]\n",
    "\n",
    "new_df = df[columns_to_keep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3c94b9eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie_id</th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "      <th>cast</th>\n",
       "      <th>keywords</th>\n",
       "      <th>runtime</th>\n",
       "      <th>release_year</th>\n",
       "      <th>language</th>\n",
       "      <th>vote_average</th>\n",
       "      <th>vote_count</th>\n",
       "      <th>new_overview</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>670347</td>\n",
       "      <td>Bone Marrow</td>\n",
       "      <td>drama</td>\n",
       "      <td>Parinaz Izadyar, Babak Hamidian, Javad Ezzati</td>\n",
       "      <td></td>\n",
       "      <td>108</td>\n",
       "      <td>2020</td>\n",
       "      <td>persian</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3</td>\n",
       "      <td>bahar has divorced her husband and is now rema...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>695675</td>\n",
       "      <td>Fox Hunting</td>\n",
       "      <td>action</td>\n",
       "      <td>Eva Huang Shengyi, Xu Jia, Eric Tsang Chi-Wai</td>\n",
       "      <td></td>\n",
       "      <td>105</td>\n",
       "      <td>2020</td>\n",
       "      <td>chinese</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1</td>\n",
       "      <td>fox hunting adapted from wang jianxing's popul...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   movie_id        title  genres  \\\n",
       "0    670347  Bone Marrow   drama   \n",
       "1    695675  Fox Hunting  action   \n",
       "\n",
       "                                            cast keywords  runtime  \\\n",
       "0  Parinaz Izadyar, Babak Hamidian, Javad Ezzati               108   \n",
       "1  Eva Huang Shengyi, Xu Jia, Eric Tsang Chi-Wai               105   \n",
       "\n",
       "   release_year language  vote_average  vote_count  \\\n",
       "0          2020  persian           6.0           3   \n",
       "1          2020  chinese           9.0           1   \n",
       "\n",
       "                                        new_overview  \n",
       "0  bahar has divorced her husband and is now rema...  \n",
       "1  fox hunting adapted from wang jianxing's popul...  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4423e725",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df= new_df.rename(columns={'new_overview':'overview'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "440e2120",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df['embedding_text']= new_df['overview']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9d92dd14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie_id</th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "      <th>cast</th>\n",
       "      <th>keywords</th>\n",
       "      <th>runtime</th>\n",
       "      <th>release_year</th>\n",
       "      <th>language</th>\n",
       "      <th>vote_average</th>\n",
       "      <th>vote_count</th>\n",
       "      <th>overview</th>\n",
       "      <th>embedding_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>862246</td>\n",
       "      <td>Mama's Dead and Lives in the Basement</td>\n",
       "      <td>mystery</td>\n",
       "      <td>Eugene Torres, June Cuthbertson</td>\n",
       "      <td>short film</td>\n",
       "      <td>5</td>\n",
       "      <td>2020</td>\n",
       "      <td>english</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>bruce gets phone calls from a woman claiming t...</td>\n",
       "      <td>bruce gets phone calls from a woman claiming t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>756167</td>\n",
       "      <td>Sitsit</td>\n",
       "      <td>horror</td>\n",
       "      <td>Ivana Alawi, Jake Cuenca, Sarah Patricia Gill</td>\n",
       "      <td></td>\n",
       "      <td>60</td>\n",
       "      <td>2020</td>\n",
       "      <td>tagalog</td>\n",
       "      <td>5.7</td>\n",
       "      <td>3</td>\n",
       "      <td>a part original movie featuring scorpio: an ag...</td>\n",
       "      <td>a part original movie featuring scorpio: an ag...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>899308</td>\n",
       "      <td>G√©rard G√©rard</td>\n",
       "      <td>comedy, romance</td>\n",
       "      <td>Pierre Hancisse, Lucie Debay, Gr√©goire Oestermann</td>\n",
       "      <td></td>\n",
       "      <td>21</td>\n",
       "      <td>2020</td>\n",
       "      <td>french</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2</td>\n",
       "      <td>abel is a ghostwriter. he just finished writin...</td>\n",
       "      <td>abel is a ghostwriter. he just finished writin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>603258</td>\n",
       "      <td>Conference</td>\n",
       "      <td>drama</td>\n",
       "      <td>Natalya Pavlenkova, Olga Lapshina, Kseniya Zueva</td>\n",
       "      <td>post-traumatic stress disorder (ptsd), sense o...</td>\n",
       "      <td>129</td>\n",
       "      <td>2020</td>\n",
       "      <td>russian</td>\n",
       "      <td>5.8</td>\n",
       "      <td>11</td>\n",
       "      <td>many years after a deadly terrorist siege in a...</td>\n",
       "      <td>many years after a deadly terrorist siege in a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>791705</td>\n",
       "      <td>Othello</td>\n",
       "      <td>drama</td>\n",
       "      <td>Michael Blake, Gordon S. Miller, Amelia Sargisson</td>\n",
       "      <td>jealousy, live theatre, filmed theater, shakes...</td>\n",
       "      <td>116</td>\n",
       "      <td>2020</td>\n",
       "      <td>english</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1</td>\n",
       "      <td>filmed version of the stratford festival produ...</td>\n",
       "      <td>filmed version of the stratford festival produ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>760793</td>\n",
       "      <td>Truth</td>\n",
       "      <td>drama</td>\n",
       "      <td>Rachel Alig, Eric Paul Erickson, Jannica Olin</td>\n",
       "      <td>civil war, criminal</td>\n",
       "      <td>107</td>\n",
       "      <td>2020</td>\n",
       "      <td>english</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>following a brutal civil war, an interrogation...</td>\n",
       "      <td>following a brutal civil war, an interrogation...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>801489</td>\n",
       "      <td>TreeTV</td>\n",
       "      <td>documentary, tv movie</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>309</td>\n",
       "      <td>2020</td>\n",
       "      <td>xx</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1</td>\n",
       "      <td>tunein on friday midnight to watch relaxing ol...</td>\n",
       "      <td>tunein on friday midnight to watch relaxing ol...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    movie_id                                  title                 genres  \\\n",
       "67    862246  Mama's Dead and Lives in the Basement                mystery   \n",
       "68    756167                                 Sitsit                 horror   \n",
       "69    899308                          G√©rard G√©rard        comedy, romance   \n",
       "70    603258                             Conference                  drama   \n",
       "71    791705                                Othello                  drama   \n",
       "72    760793                                  Truth                  drama   \n",
       "73    801489                                 TreeTV  documentary, tv movie   \n",
       "\n",
       "                                                 cast  \\\n",
       "67                    Eugene Torres, June Cuthbertson   \n",
       "68      Ivana Alawi, Jake Cuenca, Sarah Patricia Gill   \n",
       "69  Pierre Hancisse, Lucie Debay, Gr√©goire Oestermann   \n",
       "70   Natalya Pavlenkova, Olga Lapshina, Kseniya Zueva   \n",
       "71  Michael Blake, Gordon S. Miller, Amelia Sargisson   \n",
       "72      Rachel Alig, Eric Paul Erickson, Jannica Olin   \n",
       "73                                                      \n",
       "\n",
       "                                             keywords  runtime  release_year  \\\n",
       "67                                         short film        5          2020   \n",
       "68                                                          60          2020   \n",
       "69                                                          21          2020   \n",
       "70  post-traumatic stress disorder (ptsd), sense o...      129          2020   \n",
       "71  jealousy, live theatre, filmed theater, shakes...      116          2020   \n",
       "72                                civil war, criminal      107          2020   \n",
       "73                                                         309          2020   \n",
       "\n",
       "   language  vote_average  vote_count  \\\n",
       "67  english           0.0           0   \n",
       "68  tagalog           5.7           3   \n",
       "69   french           6.0           2   \n",
       "70  russian           5.8          11   \n",
       "71  english           8.0           1   \n",
       "72  english           3.0           1   \n",
       "73       xx           6.0           1   \n",
       "\n",
       "                                             overview  \\\n",
       "67  bruce gets phone calls from a woman claiming t...   \n",
       "68  a part original movie featuring scorpio: an ag...   \n",
       "69  abel is a ghostwriter. he just finished writin...   \n",
       "70  many years after a deadly terrorist siege in a...   \n",
       "71  filmed version of the stratford festival produ...   \n",
       "72  following a brutal civil war, an interrogation...   \n",
       "73  tunein on friday midnight to watch relaxing ol...   \n",
       "\n",
       "                                       embedding_text  \n",
       "67  bruce gets phone calls from a woman claiming t...  \n",
       "68  a part original movie featuring scorpio: an ag...  \n",
       "69  abel is a ghostwriter. he just finished writin...  \n",
       "70  many years after a deadly terrorist siege in a...  \n",
       "71  filmed version of the stratford festival produ...  \n",
       "72  following a brutal civil war, an interrogation...  \n",
       "73  tunein on friday midnight to watch relaxing ol...  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df.iloc[67:74]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c7cfe839",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['movie_id', 'title', 'genres', 'cast', 'keywords', 'runtime',\n",
       "       'release_year', 'language', 'vote_average', 'vote_count', 'overview',\n",
       "       'embedding_text'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0b52c9b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows: 4951\n",
      "NaNs: 0\n",
      "Non-strings: 0\n"
     ]
    }
   ],
   "source": [
    "col = new_df[\"embedding_text\"]\n",
    "\n",
    "print(\"Total rows:\", len(col))\n",
    "print(\"NaNs:\", col.isna().sum())\n",
    "print(\"Non-strings:\", sum(not isinstance(x, str) for x in col if pd.notna(x)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "67904db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# this code saves cleaned df to the below path\n",
    "\n",
    "# os.makedirs(\"../datasets/cleaned\", exist_ok=True)\n",
    "# new_df.to_csv(\"../datasets/cleaned/movies_cleaned_2.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3faedd97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "PROJECT_ROOT = Path.cwd().parents[0]  # moviebot/\n",
    "sys.path.append(str(PROJECT_ROOT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08e76181",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# ========================\n",
    "# Base paths\n",
    "# ========================\n",
    "# PROJECT_ROOT = Path(__file__).resolve().parents[2]\n",
    "\n",
    "DATASET_DIR = PROJECT_ROOT / \"datasets\" / \"cleaned\"\n",
    "MOVIES_CSV_PATH = DATASET_DIR / \"movies_cleaned.csv\"\n",
    "# MOVIES_CSV_PATH = DATASET_DIR / \"movies_cleaned_2.csv\"\n",
    "\n",
    "#=========Mood Predictor================\n",
    "MODEL_PATH = PROJECT_ROOT /\"src\" /\"models\" / \"emotion_model\"\n",
    "\n",
    "# ========================\n",
    "# Embedding configuration\n",
    "# ========================\n",
    "EMBEDDING_MODEL_NAME = \"all-mpnet-base-v2\"\n",
    "EMBEDDING_DTYPE = \"float32\"\n",
    "\n",
    "# ========================\n",
    "# FAISS configuration\n",
    "# ========================\n",
    "FAISS_INDEX_DIR = PROJECT_ROOT / \"datasets\" / \"faiss\"\n",
    "FAISS_INDEX_PATH = FAISS_INDEX_DIR / \"movies.index\"\n",
    "\n",
    "# ========================\n",
    "# Recommendation defaults\n",
    "# ========================\n",
    "TOP_K_RECOMMENDATIONS = 10\n",
    "\n",
    "# Similarity weights (used later)\n",
    "GENRE_BOOST = 0.3\n",
    "LANGUAGE_BOOST = 0.3\n",
    "POPULARITY_BOOST = 0.05\n",
    "\n",
    "YES_WORDS = [\"yes\", \"yeah\", \"yep\", \"sure\", \"okay\", \"ok\", \"Yah\", \"absolutely\", \"definitely\",\"Yes please\",\"Ya\", 'y', 'yea', \"sure\"]\n",
    "NO_WORDS = [\"no\", \"nope\", \"nah\", \"not really\", \"don't\", \"do not\",\"No thanks\",\"No thank you\", 'n', 'nah', 'noo']\n",
    "LANGUAGES = [\n",
    "    \"English\", \"Hindi\", \"Telugu\", \"Tamil\", \"Korean\",\n",
    "    \"Japanese\", \"Spanish\", \"French\", \"Persian\", \"Urdu\", \n",
    "    \"Arabic\", \"Bengali\",\"Chinese\",\"German\"\n",
    "]\n",
    "genres = [\n",
    "    \"action\",\n",
    "    \"adventure\",\n",
    "    \"animation\",\n",
    "    \"comedy\",\n",
    "    \"crime\",\n",
    "    \"documentary\",\n",
    "    \"biography\",\n",
    "    \"drama\",\n",
    "    \"family\",\n",
    "    \"fantasy\",\n",
    "    \"history\",\n",
    "    \"horror\",\n",
    "    \"music\",\n",
    "    \"mystery\",\n",
    "    \"romance\",\n",
    "    \"sci-fi\",\n",
    "    \"thriller\",\n",
    "    \"war\",\n",
    "    \"western\"\n",
    "]\n",
    "# ========================\n",
    "# Validation schema\n",
    "# ========================\n",
    "REQUIRED_COLUMNS = {\n",
    "    \"movie_id\",\n",
    "    \"title\",\n",
    "    \"embedding_text\",\n",
    "    \"genres\",\n",
    "    \"cast\",\n",
    "    \"keywords\",\n",
    "    \"runtime\",\n",
    "    \"language\",\n",
    "    \"release_year\",\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "159b9fc7",
   "metadata": {},
   "source": [
    "2. ## Creating Vector Embeddings: I define 4 helper modules in this section\n",
    "#### 2.1 movie_repository: Handles loading and querying the cleaned movie dataset.\n",
    "#### 2.2 embedding_model: Creates vector embeddings for movies dataaset using Sentence Transformer\n",
    "#### 2.3 index_builder: Builds indexes and creates mappings with movies metadata for respective embeddings\n",
    "#### 2.4 faiss_index:  builds faiss indexes from vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4ca17af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2.1 src/data/movie_repository.py\n",
    "from typing import Optional, List\n",
    "import pandas as pd\n",
    "\n",
    "# from src.config.settings import (\n",
    "#     MOVIES_CSV_PATH,\n",
    "#     REQUIRED_COLUMNS\n",
    "# )\n",
    "\n",
    "\n",
    "class MovieRepository:\n",
    "    \"\"\"\n",
    "    Handles loading and querying the cleaned movie dataset.\n",
    "    This class is the single source of truth for movie data access.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, csv_path: Optional[str] = None):\n",
    "        self.csv_path = csv_path or MOVIES_CSV_PATH\n",
    "        self._df: Optional[pd.DataFrame] = None\n",
    "\n",
    "    def load(self) -> None:\n",
    "        \"\"\"Load the movie dataset into memory.\"\"\"\n",
    "        if not self.csv_path.exists():\n",
    "            raise FileNotFoundError(\n",
    "                f\"Movie dataset not found at: {self.csv_path}\"\n",
    "            )\n",
    "\n",
    "        self._df = pd.read_csv(self.csv_path)\n",
    "        self._validate_schema()\n",
    "\n",
    "    def _validate_schema(self) -> None:\n",
    "        \"\"\"Ensure required columns exist.\"\"\"\n",
    "        if self._df is None:\n",
    "            raise RuntimeError(\"Dataset not loaded\")\n",
    "\n",
    "        missing = REQUIRED_COLUMNS - set(self._df.columns)\n",
    "        if missing:\n",
    "            raise ValueError(\n",
    "                f\"Dataset missing required columns: {missing}\"\n",
    "            )\n",
    "\n",
    "    @property\n",
    "    def df(self) -> pd.DataFrame:\n",
    "        \"\"\"Safe access to underlying dataframe.\"\"\"\n",
    "        if self._df is None:\n",
    "            raise RuntimeError(\"Call load() before accessing data\")\n",
    "        return self._df\n",
    "\n",
    "    def get_all_movies(self) -> pd.DataFrame:\n",
    "        \"\"\"Return full dataset.\"\"\"\n",
    "        return self.df.copy()\n",
    "\n",
    "    def filter_movies(\n",
    "        self,\n",
    "        language: Optional[List[str]] = None,\n",
    "        max_runtime: Optional[int] = None,\n",
    "        min_runtime: Optional[int] = None,\n",
    "    ) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Apply hard filters only (no ranking).\n",
    "        \"\"\"\n",
    "        df = self.df\n",
    "\n",
    "        if language:\n",
    "            df = df[df[\"language\"].isin(language)]\n",
    "\n",
    "        if max_runtime is not None:\n",
    "            df = df[df[\"runtime\"] <= max_runtime]\n",
    "\n",
    "        if min_runtime is not None:\n",
    "            df = df[df[\"runtime\"] >= min_runtime]\n",
    "\n",
    "        return df.copy()\n",
    "\n",
    "    def get_movie_by_id(self, movie_id: int) -> pd.Series:\n",
    "        \"\"\"Fetch a single movie by ID.\"\"\"\n",
    "        movie = self.df[self.df[\"movie_id\"] == movie_id]\n",
    "        if movie.empty:\n",
    "            raise ValueError(f\"Movie with id {movie_id} not found\")\n",
    "        return movie.iloc[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a4172cb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\projects\\moviebot-v2\\.venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "#2.2 src/models/embedding_model\n",
    "from typing import List\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# from src.config.settings import EMBEDDING_MODEL_NAME, EMBEDDING_DTYPE\n",
    "\n",
    "\n",
    "class EmbeddingModel:\n",
    "    \"\"\"\n",
    "    Wrapper around SentenceTransformer for generating embeddings.\n",
    "    Responsible ONLY for embedding text.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, model_name: str = EMBEDDING_MODEL_NAME):\n",
    "        self.model_name = model_name\n",
    "        self._model: SentenceTransformer | None = None\n",
    "\n",
    "    def load(self) -> None:\n",
    "        \"\"\"Load the embedding model into memory.\"\"\"\n",
    "        if self._model is None:\n",
    "            self._model = SentenceTransformer(self.model_name)\n",
    "\n",
    "    def embed_text(self, text: str) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Embed a single string into a vector.\n",
    "        \"\"\"\n",
    "        if not text or not isinstance(text, str):\n",
    "            raise ValueError(\"Text must be a non-empty string\")\n",
    "\n",
    "        self.load()\n",
    "\n",
    "        vector = self._model.encode(\n",
    "            text,\n",
    "            convert_to_numpy=True,\n",
    "            normalize_embeddings=True\n",
    "        )\n",
    "\n",
    "        return vector.astype(EMBEDDING_DTYPE)\n",
    "\n",
    "    def embed_texts(self, texts: List[str], batch_size: int = 32) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Embed multiple strings into a 2D array.\n",
    "        Shape: (num_texts, embedding_dim)\n",
    "        \"\"\"\n",
    "        if not texts or not isinstance(texts, list):\n",
    "            raise ValueError(\"Texts must be a non-empty list of strings\")\n",
    "\n",
    "        self.load()\n",
    "\n",
    "        vectors = self._model.encode(\n",
    "            texts,\n",
    "            batch_size=batch_size,\n",
    "            convert_to_numpy=True,\n",
    "            normalize_embeddings=True,\n",
    "            show_progress_bar=True\n",
    "        )\n",
    "\n",
    "        return vectors.astype(EMBEDDING_DTYPE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b5513322",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.3 src/index/index_builder\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from src.data.movie_repository import MovieRepository\n",
    "from src.models.embedding_model import EmbeddingModel\n",
    "from src.index.faiss_index import FaissIndex\n",
    "from src.config.settings import FAISS_INDEX_PATH\n",
    "\n",
    "\n",
    "class IndexBuilder:\n",
    "    \"\"\"\n",
    "    Builds and persists a FAISS index for movies.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        repository: MovieRepository,\n",
    "        embedding_model: EmbeddingModel,\n",
    "        index_path: Path = FAISS_INDEX_PATH,\n",
    "    ):\n",
    "        self.repository = repository\n",
    "        self.embedding_model = embedding_model\n",
    "        self.index_path = index_path\n",
    "        self.mapping_path = index_path.with_suffix(\".mapping.npy\")\n",
    "\n",
    "    def build(self) -> None:\n",
    "        \"\"\"\n",
    "        Build or append to FAISS index from movie embeddings.\n",
    "        \"\"\"\n",
    "        df = self.repository.get_all_movies()\n",
    "\n",
    "        if \"embedding_text\" not in df.columns:\n",
    "            raise ValueError(\"embedding_text column missing\")\n",
    "\n",
    "        if df.empty:\n",
    "            return\n",
    "\n",
    "        # üëâ IMPORTANT: Only embed rows we are about to add\n",
    "        texts = df[\"embedding_text\"].tolist()\n",
    "        vectors = self.embedding_model.embed_texts(texts)\n",
    "\n",
    "        # Load or create index\n",
    "        if self.index_path.exists():\n",
    "            index = FaissIndex.load(self.index_path)\n",
    "        else:\n",
    "            index = FaissIndex(dim=vectors.shape[1])\n",
    "\n",
    "        # Append vectors (THIS is the real add)\n",
    "        index.add(vectors)\n",
    "\n",
    "        # Save index first\n",
    "        index.save(self.index_path)\n",
    "\n",
    "        # Append mapping AFTER index.add()\n",
    "        self._save_mapping(df)\n",
    "\n",
    "        # Safety check\n",
    "        self._validate_index_vs_mapping(index)\n",
    "\n",
    "    def _save_mapping(self, df: pd.DataFrame) -> None:\n",
    "        \"\"\"\n",
    "        Append FAISS index ‚Üí movie_id mapping.\n",
    "        \"\"\"\n",
    "        new_movie_ids = df[\"movie_id\"].to_numpy()\n",
    "\n",
    "        self.mapping_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        if self.mapping_path.exists():\n",
    "            existing_movie_ids = np.load(self.mapping_path)\n",
    "            combined_movie_ids = np.concatenate(\n",
    "                [existing_movie_ids, new_movie_ids]\n",
    "            )\n",
    "        else:\n",
    "            combined_movie_ids = new_movie_ids\n",
    "\n",
    "        np.save(self.mapping_path, combined_movie_ids)\n",
    "\n",
    "    def _validate_index_vs_mapping(self, index: FaissIndex) -> None:\n",
    "        \"\"\"\n",
    "        Ensure FAISS index and mapping stay aligned.\n",
    "        \"\"\"\n",
    "        movie_ids = np.load(self.mapping_path)\n",
    "        if index.index.ntotal != len(movie_ids):\n",
    "            raise RuntimeError(\n",
    "                f\"FAISS index size ({index.index.ntotal}) \"\n",
    "                f\"!= mapping size ({len(movie_ids)})\"\n",
    "            )\n",
    "\n",
    "    def load_index(self) -> tuple[FaissIndex, np.ndarray]:\n",
    "        \"\"\"\n",
    "        Load FAISS index and movie_id mapping.\n",
    "        \"\"\"\n",
    "        index = FaissIndex.load(self.index_path)\n",
    "\n",
    "        if not self.mapping_path.exists():\n",
    "            raise FileNotFoundError(\n",
    "                f\"Mapping file not found at {self.mapping_path}\"\n",
    "            )\n",
    "\n",
    "        movie_ids = np.load(self.mapping_path)\n",
    "        return index, movie_ids\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0473a526",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2.4 src/index/faiss_index\n",
    "from typing import Tuple\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import faiss\n",
    "\n",
    "\n",
    "class FaissIndex:\n",
    "    \"\"\"\n",
    "    Thin wrapper around FAISS index for vector similarity search.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, dim: int):\n",
    "        \"\"\"\n",
    "        :param dim: embedding dimension (e.g. 768 for SBERT)\n",
    "        \"\"\"\n",
    "        self.dim = dim\n",
    "        self.index: faiss.Index | None = None\n",
    "\n",
    "    # -----------------------------\n",
    "    # BUILD (fresh index)\n",
    "    # -----------------------------\n",
    "    def build(self, vectors: np.ndarray) -> None:\n",
    "        \"\"\"\n",
    "        Build a NEW FAISS index from vectors.\n",
    "        This overwrites any existing index in memory.\n",
    "        \"\"\"\n",
    "        self._validate_vectors(vectors)\n",
    "\n",
    "        faiss.normalize_L2(vectors)\n",
    "\n",
    "        self.index = faiss.IndexFlatIP(self.dim)\n",
    "        self.index.add(vectors)\n",
    "\n",
    "    # -----------------------------\n",
    "    # ADD (append vectors)\n",
    "    # -----------------------------\n",
    "    def add(self, vectors: np.ndarray) -> None:\n",
    "        \"\"\"\n",
    "        Append vectors to an existing FAISS index.\n",
    "        Creates index if not present.\n",
    "        \"\"\"\n",
    "        if vectors is None or len(vectors) == 0:\n",
    "            return\n",
    "\n",
    "        self._validate_vectors(vectors)\n",
    "\n",
    "        faiss.normalize_L2(vectors)\n",
    "\n",
    "        if self.index is None:\n",
    "            self.index = faiss.IndexFlatIP(self.dim)\n",
    "\n",
    "        self.index.add(vectors)\n",
    "\n",
    "    # -----------------------------\n",
    "    # SAVE / LOAD\n",
    "    # -----------------------------\n",
    "    def save(self, path: Path) -> None:\n",
    "        \"\"\"\n",
    "        Persist FAISS index to disk.\n",
    "        \"\"\"\n",
    "        if self.index is None:\n",
    "            raise RuntimeError(\"Index has not been built or loaded\")\n",
    "\n",
    "        path.parent.mkdir(parents=True, exist_ok=True)\n",
    "        faiss.write_index(self.index, str(path))\n",
    "\n",
    "    @classmethod\n",
    "    def load(cls, path: Path) -> \"FaissIndex\":\n",
    "        \"\"\"\n",
    "        Load FAISS index from disk and return a FaissIndex instance.\n",
    "        \"\"\"\n",
    "        if not path.exists():\n",
    "            raise FileNotFoundError(f\"FAISS index not found at {path}\")\n",
    "\n",
    "        index = faiss.read_index(str(path))\n",
    "        obj = cls(dim=index.d)\n",
    "        obj.index = index\n",
    "        return obj\n",
    "\n",
    "    # -----------------------------\n",
    "    # SEARCH\n",
    "    # -----------------------------\n",
    "    def search(\n",
    "        self,\n",
    "        query_vector: np.ndarray,\n",
    "        top_k: int = 5\n",
    "    ) -> Tuple[np.ndarray, np.ndarray]:\n",
    "        \"\"\"\n",
    "        Perform similarity search.\n",
    "        \"\"\"\n",
    "        if self.index is None:\n",
    "            raise RuntimeError(\"Index not loaded or built\")\n",
    "\n",
    "        if query_vector.ndim != 1 or query_vector.shape[0] != self.dim:\n",
    "            raise ValueError(\n",
    "                f\"Expected query vector of shape ({self.dim},), got {query_vector.shape}\"\n",
    "            )\n",
    "\n",
    "        query_vector = query_vector.astype(np.float32)\n",
    "        faiss.normalize_L2(query_vector.reshape(1, -1))\n",
    "\n",
    "        scores, indices = self.index.search(\n",
    "            query_vector.reshape(1, -1),\n",
    "            top_k\n",
    "        )\n",
    "\n",
    "        return scores[0], indices[0]\n",
    "\n",
    "    # -----------------------------\n",
    "    # INTERNAL HELPERS\n",
    "    # -----------------------------\n",
    "    def _validate_vectors(self, vectors: np.ndarray) -> None:\n",
    "        if vectors.ndim != 2:\n",
    "            raise ValueError(f\"Vectors must be 2D, got {vectors.shape}\")\n",
    "\n",
    "        if vectors.shape[1] != self.dim:\n",
    "            raise ValueError(\n",
    "                f\"Vector dim {vectors.shape[1]} != index dim {self.dim}\"\n",
    "            )\n",
    "\n",
    "        if vectors.dtype != np.float32:\n",
    "            raise ValueError(\"Vectors must be float32\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9658238",
   "metadata": {},
   "source": [
    "### 3. LLMs for interpretting user's text\n",
    "I integrated LLMs using Gemini API, API Key  for calling Gemini model for interpretting mood predicting genres, extracting movie plot based on user's movie preference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "59ba34fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both GOOGLE_API_KEY and GEMINI_API_KEY are set. Using GOOGLE_API_KEY.\n"
     ]
    }
   ],
   "source": [
    "# 3 src/llm/extract_movie_info\n",
    "\n",
    "from typing import List\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class Movie(BaseModel):\n",
    "    \"\"\"Structured data about a movie.\"\"\"\n",
    "    title: str = Field(description=\"The full title of the movie.\")\n",
    "    themes: List[str] = []\n",
    "    plot: str  = Field(description=\"brief plot describing movie intent\")\n",
    "\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from src.movie import Movie\n",
    "from google import genai\n",
    "import os\n",
    "from google.genai.errors import APIError\n",
    "\n",
    "try:\n",
    "    load_dotenv()\n",
    "    GEMINI_API_KEY = os.getenv(\"GEMINI_API_KEY\") # enter your gemini api key here\n",
    "    client = genai.Client(api_key=GEMINI_API_KEY)\n",
    "except Exception as e:\n",
    "    print(f\"Error initializing Gemini client: {e}\")\n",
    "    client = None\n",
    "\n",
    "def extract_movie_info(text: str):\n",
    "    if not client:\n",
    "      print(\"Gemini client not initialized. Check API key setup.\")\n",
    "      return None\n",
    "    prompt = f\"\"\"\n",
    "From the USER TEXT, perform the following steps:\n",
    "\n",
    "1. Check whether the USER TEXT explicitly mentions a real movie, TV show, or web series\n",
    "   (even partially or informally).\n",
    "\n",
    "2. IF a real movie, TV show, or web series is identified:\n",
    "   - Set official_title to the recognized title\n",
    "   - Generate 3‚Äì6 concise theme keywords that reflect the tone or subject\n",
    "   - Write ONE clear sentence describing the plot or narrative intent of the identified title\n",
    "\n",
    "3. IF NO real movie, TV show, or web series is identified:\n",
    "   - Leave official_title EMPTY\n",
    "   - Extract themes ONLY if clearly implied by the text\n",
    "   - IF the USER TEXT expresses a general movie preference or intent\n",
    "     (for example: \"movie with Christmas theme\", \"feel-good romantic comedy\",\n",
    "      \"high school comedy\", \"thriller set in winter\"),\n",
    "     THEN copy the USER TEXT verbatim into the plot field\n",
    "   - Otherwise, leave the plot field EMPTY\n",
    "\n",
    "Return a JSON object only. Do not add explanations.\n",
    "\n",
    "USER TEXT: \"{text}\" \"\"\"\n",
    "\n",
    "\n",
    "\n",
    "    try:\n",
    "        # Call the API with the structured output configuration\n",
    "        response = client.models.generate_content(\n",
    "            model=\"gemini-2.5-flash-lite\",\n",
    "            contents=[prompt],\n",
    "            config={\n",
    "                #    'system_instruction': system_msg,\n",
    "                   'response_mime_type': 'application/json',\n",
    "                'response_schema': Movie,\n",
    "            }\n",
    "        )\n",
    "        extracted_movie = Movie.model_validate_json(response.text)\n",
    "        return extracted_movie\n",
    "    # except APIError as e:\n",
    "    #     print(f\"Gemini API Error (Check Quota/Rate Limits): {e}\")\n",
    "    #     return None\n",
    "    except Exception as e:\n",
    "        print(f\"Error generating content: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "# res = extract_movie_info(\" I want something like stranger things dark thriller type\")\n",
    "# # print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b0bdbeb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both GOOGLE_API_KEY and GEMINI_API_KEY are set. Using GOOGLE_API_KEY.\n"
     ]
    }
   ],
   "source": [
    "# 3 src/llm/give_customized_mood_Response\n",
    "# gives response and genres user might like based on user's mood\n",
    "\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class MovieGenre(BaseModel):\n",
    "    \"\"\"Structured data about a movie.\"\"\"\n",
    "    response_text: str = Field(description=\"The customized response text based on mood.\")\n",
    "    genres: list = Field(description=\"list of genres associated with the mood.\")\n",
    "\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from src.mood_genre import MovieGenre\n",
    "from google import genai\n",
    "import os\n",
    "# from google.genai.errors import APIError\n",
    "\n",
    "try:\n",
    "    load_dotenv()\n",
    "    # GEMINI_API_KEY = os.getenv(\"GEMINI_API_KEY\")\n",
    "    GEMINI_API_KEY = 'AIzaSyCHrN533OwfanNjCscx2dZbE4o9T0_j0sg' \n",
    "    client = genai.Client(api_key=GEMINI_API_KEY)\n",
    "except Exception as e:\n",
    "    print(f\"Error initializing Gemini client: {e}\")\n",
    "    client = None\n",
    "\n",
    "def give_customized_mood_response(text: str):\n",
    "    if not client:\n",
    "      print(\"Gemini client not initialized. Check API key setup.\")\n",
    "      return None\n",
    "    \n",
    "    if len(text)==0:\n",
    "        return None\n",
    "    prompt = (f\"Based on the user text analyze the mood he is in and suggest movie genres he might like. The response_text must contain customized response something like: Since you are in a mood to watch so and so\"\n",
    "            f\"I want you to output a json with response_text as string and standardised genres as a list of strings in lowercase do not output none values, output empty string if no genre or no response_text \\n\\Mood: \\\"{text}\\\"\")\n",
    "    try:\n",
    "        # Call the API with the structured output configuration\n",
    "        response = client.models.generate_content(\n",
    "            model=\"gemini-2.5-flash\",\n",
    "\n",
    "            contents=[prompt],\n",
    "            config={\n",
    "                   'response_mime_type': 'application/json',\n",
    "                'response_schema': MovieGenre,\n",
    "            }\n",
    "        )\n",
    "        extracted_response = MovieGenre.model_validate_json(response.text)\n",
    "        return extracted_response\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error generating content: {e}\")\n",
    "        return None\n",
    "    \n",
    "\n",
    "    # except APIError as e:\n",
    "    #     print(f\"Gemini API Error (Check Quota/Rate Limits): {e}\")\n",
    "    #     return None\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred: {e}\")\n",
    "        return None\n",
    "    \n",
    "\n",
    "# res = give_customized_mood_response(\"light, uplifting\")\n",
    "# print(f\"{res.response_text} {','.join(res.genres)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "977a2bef",
   "metadata": {},
   "source": [
    "### 4. Create reranker module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e75681e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# src/models/reranker_model\n",
    "from sentence_transformers import CrossEncoder\n",
    "import numpy as np\n",
    "from typing import List, Tuple\n",
    "\n",
    "class ReRankerModel:\n",
    "    \"\"\"\n",
    "    Wrapper for Cross-Encoder models to re-rank candidates.\n",
    "    \"\"\"\n",
    "    def __init__(self, model_name: str = \"cross-encoder/ms-marco-MiniLM-L-6-v2\"):\n",
    "        self.model_name = model_name\n",
    "        self._model: CrossEncoder | None = None\n",
    "\n",
    "    def load(self) -> None:\n",
    "        if self._model is None:\n",
    "            self._model = CrossEncoder(self.model_name)\n",
    "\n",
    "    def rank(self, query: str, documents: List[str]) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Returns a relevance score for each document relative to the query.\n",
    "        \"\"\"\n",
    "        if not documents:\n",
    "            return np.array([])\n",
    "            \n",
    "        self.load()\n",
    "        # Create pairs: [[query, doc1], [query, doc2]...]\n",
    "        pairs = [[query, doc] for doc in documents]\n",
    "        scores = self._model.predict(pairs)\n",
    "        return scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ee229b2",
   "metadata": {},
   "source": [
    "### 5. Recommendation Module: \n",
    "This module searches user's query with FAISS embeddings calculates similarity index, uses reranker module to rerank results, applies heard filters on language, gives soft boosts on Genre to improve similarity score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "299331d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# src/recommender/recommendation_engine\n",
    "from typing import List, Dict, Any\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import Optional\n",
    "from src.models.reranker_model import ReRankerModel\n",
    "from src.models.embedding_model import EmbeddingModel\n",
    "from src.index.faiss_index import FaissIndex\n",
    "from src.data.movie_repository import MovieRepository\n",
    "from src.config.settings import (\n",
    "    TOP_K_RECOMMENDATIONS,\n",
    "    GENRE_BOOST,\n",
    "    POPULARITY_BOOST,\n",
    ")\n",
    "GENRE_BOOST = 0.3 #can adjust accordingly\n",
    "POPULARITY_BOOST = 0.05\n",
    "TOP_K_RECOMMENDATIONS = 10\n",
    "\n",
    "class RecommendationEngine:\n",
    "    \"\"\"\n",
    "    Core recommendation engine combining semantic similarity,\n",
    "    hard filters, and soft ranking boosts.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        repository: MovieRepository,\n",
    "        embedding_model: EmbeddingModel,\n",
    "        faiss_index: FaissIndex,\n",
    "        index_to_movie_id: np.ndarray,\n",
    "        reranker: ReRankerModel,\n",
    "    ):\n",
    "        self.repository = repository\n",
    "        self.embedding_model = embedding_model\n",
    "        self.index = faiss_index\n",
    "        self.index_to_movie_id = index_to_movie_id\n",
    "        self.reranker = reranker\n",
    "\n",
    "    def recommend(\n",
    "        self,\n",
    "        user_profile: Dict[str, Any],\n",
    "        top_k: int = TOP_K_RECOMMENDATIONS,\n",
    "        faiss_k: int = 50,\n",
    "    ) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Generate movie recommendations.\n",
    "        \"\"\"\n",
    "        query_text = user_profile.get(\"query_text\")\n",
    "        # intents = user_profile.get('intent_terms')\n",
    "        if not query_text:\n",
    "            raise ValueError(\"query_text is required\")\n",
    "\n",
    "        # 1. Embed user query\n",
    "        text_to_embed = query_text\n",
    "        query_vector = self.embedding_model.embed_text(text_to_embed)\n",
    "\n",
    "        # 2. FAISS retrieval\n",
    "        scores, indices = self.index.search(query_vector, top_k=faiss_k)\n",
    "\n",
    "        candidate_ids = self.index_to_movie_id[indices]\n",
    "        df_candidates = self.repository.df[\n",
    "            self.repository.df[\"movie_id\"].isin(candidate_ids)\n",
    "        ].copy()\n",
    "\n",
    "        # Attach similarity scores\n",
    "        score_map = dict(zip(candidate_ids, scores))\n",
    "        df_candidates[\"similarity_score\"] = df_candidates[\"movie_id\"].map(score_map)\n",
    "\n",
    "        # 3. Hard filters\n",
    "        df_candidates = self._apply_hard_filters(\n",
    "            df_candidates,\n",
    "            user_profile\n",
    "        )\n",
    "\n",
    "        if df_candidates.empty:\n",
    "            return df_candidates\n",
    "        \n",
    "        if self.reranker and not df_candidates.empty:\n",
    "            documents = df_candidates[\"embedding_text\"].fillna(\"\").tolist()\n",
    "\n",
    "            rerank_scores = self.reranker.rank(\n",
    "                query=query_text,\n",
    "                documents=documents\n",
    "            )\n",
    "\n",
    "            df_candidates[\"rerank_score\"] = rerank_scores\n",
    "\n",
    "            # Combine FAISS similarity + reranker score\n",
    "            df_candidates[\"final_score\"] = (\n",
    "                0.6 * df_candidates[\"similarity_score\"]\n",
    "                + 0.4 * df_candidates[\"rerank_score\"]\n",
    "            )\n",
    "        else:\n",
    "            df_candidates[\"final_score\"] = df_candidates[\"similarity_score\"]\n",
    "\n",
    "        # 4. Soft boosts\n",
    "        df_candidates[\"final_score\"] = df_candidates[\"similarity_score\"]\n",
    "        df_candidates[\"final_score\"] += self._genre_boost(\n",
    "            df_candidates,\n",
    "            user_profile.get(\"genres\")\n",
    "        )\n",
    "        df_candidates[\"final_score\"] += self._popularity_boost(df_candidates)\n",
    "        df_candidates = df_candidates.drop_duplicates(subset=['movie_id'])\n",
    "\n",
    "        # 5. Rank & return\n",
    "        return (\n",
    "            df_candidates\n",
    "            .sort_values(\"final_score\", ascending=False)\n",
    "            .head(top_k)\n",
    "            .reset_index(drop=True)\n",
    "        )\n",
    "\n",
    "    # -----------------------\n",
    "    # Hard filters\n",
    "    # -----------------------\n",
    "\n",
    "    def _apply_hard_filters(\n",
    "        self,\n",
    "        df: pd.DataFrame,\n",
    "        user_profile: Dict[str, Any],\n",
    "    ) -> pd.DataFrame:\n",
    "        languages = user_profile.get(\"language\")\n",
    "        # runtime = user_profile.get(\"runtime\", {})\n",
    "\n",
    "        if languages:\n",
    "            df = df[df[\"language\"].isin(languages)]\n",
    "\n",
    "        # if runtime:\n",
    "        #     if runtime.get(\"max\") is not None:\n",
    "        #         df = df[df[\"runtime\"] <= runtime[\"max\"]]\n",
    "        #     if runtime.get(\"min\") is not None:\n",
    "        #         df = df[df[\"runtime\"] >= runtime[\"min\"]]\n",
    "        #     if runtime.get(\"exact\") is not None:\n",
    "        #         df = df[df[\"runtime\"] == runtime[\"exact\"]]\n",
    "            \n",
    "        # if not runtime:\n",
    "        #     df = df[df['runtime'] >= 50]\n",
    "\n",
    "        return df\n",
    "\n",
    "    # -----------------------\n",
    "    # Soft boosts\n",
    "    # -----------------------\n",
    "\n",
    "    def _genre_boost(\n",
    "        self,\n",
    "        df: pd.DataFrame,\n",
    "        preferred_genres: Optional[List[str]],\n",
    "    ) -> np.ndarray:\n",
    "        if not preferred_genres:\n",
    "            return 0.0\n",
    "\n",
    "        def match(genres: str) -> float:\n",
    "            if not isinstance(genres, str):\n",
    "                return 0.0\n",
    "            movie_genres = set(genres.split(\",\"))\n",
    "            return GENRE_BOOST if movie_genres & set(preferred_genres) else 0.0\n",
    "\n",
    "        return df[\"genres\"].apply(match)\n",
    "\n",
    "    def _popularity_boost(self, df: pd.DataFrame) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Light popularity boost using vote_average.\n",
    "        \"\"\"\n",
    "        if \"vote_average\" not in df.columns:\n",
    "            return 0.0\n",
    "\n",
    "        # Normalize to 0‚Äì1 range\n",
    "        votes = df[\"vote_average\"].fillna(0)\n",
    "        norm = (votes - votes.min()) / (votes.max() - votes.min() + 1e-6)\n",
    "\n",
    "        return norm * POPULARITY_BOOST\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a1e7c89",
   "metadata": {},
   "source": [
    "### 6.Conversation Manager Module:\n",
    "I define a state class that manages all variables,  defined helper modules:\n",
    "\n",
    "6.1 ConversationState -> state class that defines objects or fields in state machine\n",
    "\n",
    "6.2 interpreter -> interprets users text, like: mood , genres selected, languages, \n",
    "\n",
    "6.3 ConversatioManager -> manages conversation state, asks questions processes text\n",
    "\n",
    "6.4 get_useful_info: -> converts users preferences to a dictionary that can be fed to recommender module\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "fdb32618",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6.1 # src/conversation_state.py\n",
    "\n",
    "from dataclasses import dataclass, field\n",
    "from typing import List, Optional\n",
    "\n",
    "from src.mood_genre import MovieGenre\n",
    "\n",
    "@dataclass\n",
    "class ConversationState:\n",
    "    mood: Optional[str] = None\n",
    "    suggested_genres: List[str] = field(default_factory=list)\n",
    "    selected_genres: List[str] = None\n",
    "    movie_description: str = None\n",
    "    language: Optional[str] = None\n",
    "    res: Optional[MovieGenre] = None\n",
    "    current_step: str = \"ask_mood\"\n",
    "    is_complete = False\n",
    "\n",
    "    def clear(self):\n",
    "        self.__init__()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "309f59e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6.2 interpreter\n",
    "# src/interpreter.py\n",
    "\n",
    "import re\n",
    "import requests\n",
    "import nltk\n",
    "# from spellchecker import SpellChecker\n",
    "from rapidfuzz import fuzz\n",
    "from thefuzz import process\n",
    "import pycountry\n",
    "import spacy\n",
    "import re\n",
    "from typing import Optional, Dict, Any\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "# from src.config.settings import genres,YES_WORDS,NO_WORDS, LANGUAGES\n",
    "# from src.llm.extract_movie_info import extract_movie_info\n",
    "\n",
    "# spell = SpellChecker()\n",
    "\n",
    "\n",
    "\n",
    "try:\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "except OSError:\n",
    "    print(\"Error: Model 'en_core_web_sm' not found. Please run 'python -m spacy download en_core_web_sm'\")\n",
    "    exit()\n",
    "\n",
    "\n",
    "try:\n",
    "    stopwords.words('english')\n",
    "except LookupError as e:\n",
    "    print(\"Downloading NLTK stopwords...\", e)\n",
    "\n",
    "\n",
    "# Define the stop words set globally for maximum efficiency\n",
    "STOP_WORDS_SET = set(stopwords.words('english'))\n",
    "\n",
    "\n",
    "def extract_plot_text(text: str, state) -> str:\n",
    "    if not text:\n",
    "        return text\n",
    "    \n",
    "    plot=''\n",
    "    enriched = extract_movie_info(text)\n",
    "    if not enriched:\n",
    "        return text\n",
    "    \n",
    "    if enriched.plot:\n",
    "      plot = str(enriched.plot).strip()\n",
    "\n",
    "    # print(\"========enriched plot========\",plot, enriched.themes )\n",
    "\n",
    "    if enriched.themes:\n",
    "        themes= ', '.join([a for a in enriched.themes])\n",
    "        plot += themes\n",
    "\n",
    "    return plot\n",
    "\n",
    "\n",
    "   \n",
    "\n",
    "def remove_stopwords(text: str) -> str:\n",
    "   word_tokens = word_tokenize(text.lower()) # Convert to lowercase first\n",
    "   \n",
    "   filtered_sentence = [w for w in word_tokens if w.isalnum() and w not in STOP_WORDS_SET]\n",
    " #  print(filtered_sentence)\n",
    "   return ' '.join(filtered_sentence)\n",
    "\n",
    "\n",
    "def detect_yes_no(text: str):\n",
    " text = text.lower().strip() if text is not None else ''\n",
    "\n",
    "    # 1. IMMEDIATE CHECK: Exact Match\n",
    "    # If the user types a perfect match, we return immediately.\n",
    " if text in YES_WORDS:\n",
    "     return \"yes\"\n",
    " if text in NO_WORDS:\n",
    "        return \"no\"\n",
    " best_yes_score = 0\n",
    " for w in YES_WORDS:\n",
    "        score = fuzz.ratio(w, text)\n",
    "        if score > best_yes_score:\n",
    "            best_yes_score = score\n",
    "            \n",
    "    # Check against NO words\n",
    " best_no_score = 0\n",
    " for w in NO_WORDS:\n",
    "        score = fuzz.ratio(w, text)\n",
    "        if score > best_no_score:   \n",
    "            best_no_score = score\n",
    "\n",
    "    # Decision Logic: Check if the best score meets the threshold\n",
    "    # and is significantly better than the opposing category.\n",
    "    \n",
    " if best_yes_score >= 80 and best_yes_score > best_no_score:\n",
    "        return \"yes\"\n",
    "    \n",
    " if best_no_score >= 80 and best_no_score > best_yes_score:\n",
    "        return \"no\"\n",
    "\n",
    " return None\n",
    "\n",
    "\n",
    "# -------------------------------\n",
    "# Genre extraction\n",
    "# -------------------------------\n",
    "def extract_genre(text: str):\n",
    "    CORRECT_GENRES = [ g.lower() for g in genres]\n",
    "    lowercased_text=text.lower()\n",
    "    cleaned_text=remove_stopwords(lowercased_text)\n",
    "\n",
    "    candidates = re.split(r'[,\\s-]+', cleaned_text)\n",
    "    best_matches = [process.extractOne(c, CORRECT_GENRES) for c in candidates]\n",
    "   # candidates = [word for word in text.lower().split() if len(word) > 2]\n",
    "    # Extract the corrected name if the score is above the threshold (85)\n",
    "    # print(best_matches)\n",
    "    corrected_genres = [match[0] for match in best_matches if match[1] > 80]\n",
    "    \n",
    "    # Return unique, correctly spelled genres\n",
    "\n",
    "    if len(corrected_genres) ==0:\n",
    "        return None\n",
    "    return list(set(corrected_genres))\n",
    "\n",
    "\n",
    "def extract_language(text: str):\n",
    "    result = detect_yes_no(text)\n",
    "\n",
    "    if result =='no':\n",
    "        return None\n",
    "    CORRECT_LANG = [ l.lower() for l in LANGUAGES]\n",
    "  #  candidates = [word for word in text.lower().split() if len(word) > 2]\n",
    "    lowercased_text=text.lower() if text is not None else ''\n",
    "    cleaned_text=remove_stopwords(lowercased_text)\n",
    "    candidates = re.split(r'[,\\s-]+', cleaned_text)\n",
    "    best_matches = [process.extractOne(c, CORRECT_LANG) for c in candidates]\n",
    "    \n",
    "    # Extract the corrected name if the score is above the threshold (85)\n",
    "    corrected_languages = [match[0] for match in best_matches if match[1] > 75]\n",
    "    if len(corrected_languages) ==0:\n",
    "        return None\n",
    "    \n",
    "    # Return unique, correctly spelled genres\n",
    "    return list(set(corrected_languages))\n",
    "\n",
    "\n",
    "\n",
    "all_language_names = [language.name for language in pycountry.languages]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# def extract_runtime(text: str) -> Optional[Dict[str, Any]]:\n",
    "#     text= text if text is not None else None\n",
    "#     t = text.lower().strip()\n",
    "\n",
    "#     # ---------------------------------\n",
    "#     # 1) Detect constraint type (symbols first)\n",
    "#     # ---------------------------------\n",
    "\n",
    "#     result = detect_yes_no(t)\n",
    "\n",
    "#     if result == 'no':\n",
    "#         return None\n",
    "    \n",
    "#     if re.search(r\"(<=|<)\", t):\n",
    "#         ctype = \"max\"\n",
    "#     elif re.search(r\"(>=|>)\", t):\n",
    "#         ctype = \"min\"\n",
    "#     elif re.search(r\"(under|below|less\\s+than|at\\s+most|within|no\\s+more\\s+than)\", t):\n",
    "#         ctype = \"max\"\n",
    "#     elif re.search(r\"(over|greater\\s+than|more\\s+than|at\\s+least|minimum|min\\.?)\", t):\n",
    "#         ctype = \"min\"\n",
    "#     else:\n",
    "#         ctype = \"exact\"\n",
    "\n",
    "#     # ---------------------------------\n",
    "#     # 2) Parse runtime and convert to minutes\n",
    "#     # ---------------------------------\n",
    "#     minutes = None\n",
    "\n",
    "#     # handles: \"1h 30m\", \"1 hr 20 min\", \"2h\", \"45m\"\n",
    "#     hm = re.search(\n",
    "#         r\"(?:(\\d+(?:\\.\\d+)?)\\s*(h|hr|hrs|hour|hours))?\\s*\"\n",
    "#         r\"(?:(\\d+(?:\\.\\d+)?)\\s*(m|min|mins|minute|minutes))?\",\n",
    "#         t\n",
    "#     )\n",
    "#     if hm and (hm.group(1) or hm.group(3)):\n",
    "#         hours = float(hm.group(1)) if hm.group(1) else 0\n",
    "#         mins = float(hm.group(3)) if hm.group(3) else 0\n",
    "#         minutes = int(round(hours * 60 + mins))\n",
    "\n",
    "#     # handles: \"< 30 mins\", \"> 2 hours\", \"less than 90 minutes\"\n",
    "#     if minutes is None:\n",
    "#         m = re.search(\n",
    "#             r\"(<=|>=|<|>|under|greater\\s+than|below|less\\s+than|over|more\\s+than|at\\s+least|at\\s+most)?\\s*\"\n",
    "#             r\"(\\d+(?:\\.\\d+)?)\\s*(h|hr|hrs|hour|hours|m|min|mins|minute|minutes)\\b\",\n",
    "#             t\n",
    "#         )\n",
    "#         if m:\n",
    "#             val = float(m.group(2))\n",
    "#             unit = m.group(3)\n",
    "#             minutes = int(round(val * 60)) if unit.startswith(\"h\") else int(round(val))\n",
    "\n",
    "#     if minutes is None:\n",
    "#         return None\n",
    "\n",
    "#     return {\"type\": ctype, \"minutes\": minutes}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "537a3cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6.3  src/conversation/conversation_manager\n",
    "# src/conversation_manager.py\n",
    "# from src.llm.give_customized_mood_response import give_customized_mood_response\n",
    "# from src.conversation.state import ConversationState\n",
    "# from src.conversation.interpreter import (\n",
    "#     extract_genre, detect_yes_no, extract_language, extract_plot_text)\n",
    "\n",
    "#from src.predict_mood import predict_mood\n",
    "class ConversationManager:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.state = ConversationState()\n",
    "\n",
    "\n",
    "    def next_question(self, state):\n",
    "        step = state.current_step\n",
    "\n",
    "        if step == \"ask_mood\":\n",
    "            return \"What's your mood today, I can recommend you geners you might like üßô‚Äç‚ôÇÔ∏è\"\n",
    "        \n",
    "        if step == \"print_mood_response\":\n",
    "            if  state.selected_genres is None:\n",
    "              predicted_genres = ','.join([a for a in state.suggested_genres])\n",
    "              return f\"{state.res.response_text}, predicted genres:{predicted_genres} \\n  Enter if any other prefered genre else type no..\"\n",
    "            else:\n",
    "                state.current_step = 'ask_language'\n",
    "                return ( f\"Gotcha! noted that you are interested in: {','.join(state.selected_genre)}.\"\n",
    "                        f\"Enter language preference if any else type no\"\n",
    "                )\n",
    "        \n",
    "        \n",
    "        if step == \"similar_movies\":\n",
    "            return \"Please share a similar movie's name or plot description to help me understand your taste better:\"\n",
    "    \n",
    "        if step == \"ask_language\":\n",
    "            return \"Please enter prefered language if any else type: 'no'\"\n",
    "\n",
    "\n",
    "        return None\n",
    "\n",
    "    def update_state(self, state, user_input):\n",
    "        text = user_input.lower()\n",
    "\n",
    "        if not len(text):\n",
    "            return \"Please enter valid input, type 'exit' to quit\"\n",
    "\n",
    "        if state.current_step == \"ask_mood\":\n",
    "\n",
    "            genres = extract_genre(text) if  extract_genre(text) else None\n",
    "\n",
    "            response_generated= give_customized_mood_response(text)\n",
    "\n",
    "            state.suggested_genres = response_generated.genres\n",
    "            state.selected_genre = genres\n",
    "            state.current_step = \"print_mood_response\"\n",
    "            state.res = response_generated\n",
    "            return state\n",
    "\n",
    "        if state.current_step == \"print_mood_response\":\n",
    "\n",
    "            yn= detect_yes_no(user_input)\n",
    "            if yn == \"no\":\n",
    "                state.selected_genre = None\n",
    "\n",
    "            else:\n",
    "                genre = extract_genre(user_input)\n",
    "                # print(\"=====selected genre\", genre)\n",
    "                state.current_step \n",
    "                state.selected_genres = genre\n",
    "           \n",
    "            state.current_step = \"ask_language\"\n",
    "            return state\n",
    "\n",
    "\n",
    "\n",
    "        if state.current_step == \"ask_language\":\n",
    "            yn= detect_yes_no(user_input)\n",
    "            if yn == \"no\":\n",
    "                state.language = None\n",
    "            else:\n",
    "                language = extract_language(user_input)\n",
    "                state.language = language\n",
    "            state.current_step = \"similar_movies\"\n",
    "            return state\n",
    "        \n",
    "        if state.current_step == \"similar_movies\":\n",
    "            state.movie_description =extract_plot_text(user_input, state)\n",
    "            state.current_step = \"reached_end\"\n",
    "            return state\n",
    "  \n",
    "\n",
    "        # if state.current_step == \"ask_language_value\":\n",
    "        #   #  language_text= correct_spelling(user_input)\n",
    "        #     state.language = extract_language(user_input)\n",
    "        #     state.current_step = \"ask_runtime\"\n",
    "        #     return state\n",
    "\n",
    "        # if state.current_step == \"ask_runtime\":\n",
    "        #     yn= detect_yes_no(user_input)\n",
    "        #     # print(\"========yn value for runtime:\", yn)\n",
    "        #     if yn == \"no\":\n",
    "        #         state.runtime = None\n",
    "        #     else:\n",
    "        #         runtime = extract_runtime(user_input)\n",
    "        #         state.runtime = runtime\n",
    "        #     state.current_step =\"runtime_done\"\n",
    "        #     return state\n",
    "\n",
    "\n",
    "\n",
    "        return state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "267d72ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6.4 src/conversation/get_useful_info \n",
    "\n",
    "# from src.conversation.state import ConversationState\n",
    "\n",
    "\n",
    "def get_useful_info(state: ConversationState) -> dict:\n",
    "    info = {\n",
    "        \"query_text\": state.movie_description if state.movie_description else '',\n",
    "        \"genres\": list(state.selected_genres) if state.selected_genres else list(state.suggested_genres),\n",
    "        \"language\": list(state.language) if state.language else [],\n",
    "        # \"runtime\": state.runtime if state.runtime else None\n",
    "    }\n",
    "    return info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc4ef911",
   "metadata": {},
   "source": [
    "### 7. Chatbot Service: Which is the orchestrator of Conversation manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ef274de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from src.conversation.conversation_manager import ConversationManager\n",
    "# from src.conversation.state import ConversationState\n",
    "from typing import Union\n",
    "\n",
    "class ChatbotService():\n",
    "\n",
    "    def __init__(self):\n",
    "\n",
    "        self.waiting_for_answer = False\n",
    "        self.state = ConversationState()\n",
    "        self.manager = ConversationManager()\n",
    "        \n",
    "\n",
    "    def run_chatbot(self):\n",
    "        print(\"\\nHowdy! I am your movie assistant Nova!\\n\")\n",
    "\n",
    "        self.state = ConversationState()\n",
    "        self.manager = ConversationManager()\n",
    "\n",
    "        while self.state.current_step != \"reached_end\":\n",
    "            question = self.manager.next_question(self.state)\n",
    "            if question:\n",
    "                  print(\"\\nNova:\", question)\n",
    "            user_input = input(\"You: \")\n",
    "            if user_input.lower() in [\"exit\", \"quit\", \"q\", \"bye\"]:\n",
    "               print(\"Exiting the conversation. Goodbye!\")\n",
    "               break\n",
    "            elif user_input.strip() == \"\":\n",
    "               print(\"Please provide a valid response.\")\n",
    "               continue\n",
    "            else:\n",
    "              self.state = self.manager.update_state(self.state, user_input)\n",
    "\n",
    "        print(\"\\n--- Conversation Complete ---\")\n",
    "        print(\"Final state to feed recommender:\\n\")\n",
    "        return self.state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3f88d0b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both GOOGLE_API_KEY and GEMINI_API_KEY are set. Using GOOGLE_API_KEY.\n",
      "Both GOOGLE_API_KEY and GEMINI_API_KEY are set. Using GOOGLE_API_KEY.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Howdy! I am your movie assistant Nova!\n",
      "\n",
      "\n",
      "Nova: What's your mood today, I can recommend you geners you might like üßô‚Äç‚ôÇÔ∏è\n",
      "\n",
      "Nova: Since you've had a stressful day, I recommend something light and uplifting to help you unwind., predicted genres:comedy,feel-good,slice of life \n",
      "  Enter if any other prefered genre else type no..\n",
      "=====selected genre ['fantasy']\n",
      "\n",
      "Nova: Please enter prefered language if any else type: 'no'\n",
      "\n",
      "Nova: Please share a similar movie's name or plot description to help me understand your taste better:\n",
      "========enriched plot======== A young orphan discovers he is a wizard and is invited to attend Hogwarts School of Witchcraft and Wizardry, where he uncovers a dark plot. ['magic', 'fantasy', 'adventure', 'friendship']\n",
      "\n",
      "--- Conversation Complete ---\n",
      "Final state to feed recommender:\n",
      "\n",
      "User Profile for Recommendations: {'query_text': 'A young orphan discovers he is a wizard and is invited to attend Hogwarts School of Witchcraft and Wizardry, where he uncovers a dark plot.magic, fantasy, adventure, friendship', 'genres': ['fantasy'], 'language': ['english']}\n",
      "\n",
      " There you Go! üé¨ Here are some recommended movies for you!:\n",
      "\n",
      "1. Wendy (Score: 0.854)\n",
      "   Genres: fantasy, drama\n",
      "   Runtime: 111 mins\n",
      "\n",
      "2. Bad Witch (Score: 0.635)\n",
      "   Genres: horror, comedy\n",
      "   Runtime: 85 mins\n",
      "\n",
      "3. Chemical Hearts (Score: 0.597)\n",
      "   Genres: drama, romance\n",
      "   Runtime: 93 mins\n",
      "\n",
      "4. Big Time Adolescence (Score: 0.594)\n",
      "   Genres: comedy, drama\n",
      "   Runtime: 91 mins\n",
      "\n",
      "5. Roald Dahl's The Witches (Score: 0.575)\n",
      "   Genres: comedy, fantasy, family, horror\n",
      "   Runtime: 104 mins\n",
      "\n",
      "6. Fall Nights in China Grove (Score: 0.569)\n",
      "   Genres: crime, drama\n",
      "   Runtime: 78 mins\n",
      "\n",
      "7. Original Gangster (Score: 0.568)\n",
      "   Genres: crime\n",
      "   Runtime: 110 mins\n",
      "\n",
      "8. My Daughter's Psycho Friend (Score: 0.567)\n",
      "   Genres: tv movie, drama\n",
      "   Runtime: 84 mins\n",
      "\n",
      "9. The Familiars (Score: 0.560)\n",
      "   Genres: horror\n",
      "   Runtime: 16 mins\n",
      "\n",
      "10. Shepard (Score: 0.541)\n",
      "   Genres: drama, thriller\n",
      "   Runtime: 70 mins\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "from src.models.reranker_model import ReRankerModel\n",
    "from src.conversation.get_useful_info import get_useful_info\n",
    "from src.chatbotservice.chatbot_service import ChatbotService\n",
    "\n",
    "from src.data.movie_repository import MovieRepository\n",
    "from src.models.embedding_model import EmbeddingModel\n",
    "from src.index.index_builder import IndexBuilder\n",
    "from src.recommender.recommendation_engine import RecommendationEngine\n",
    "\n",
    "\n",
    "\n",
    "def print_recommendations(df):\n",
    "    print(\"\\n There you Go! üé¨ Here are some recommended movies for you!:\\n\")\n",
    "    for i, row in df.iterrows():\n",
    "        print(\n",
    "            f\"{i+1}. {row['title']} \"\n",
    "            f\"(Score: {row['final_score']:.3f})\"\n",
    "        )\n",
    "        \n",
    "        # Check if genres is a string; if not (like NaN), use \"Unknown\"\n",
    "        raw_genres = row['genres']\n",
    "        if isinstance(raw_genres, str):\n",
    "            genres_list = raw_genres.split('|')\n",
    "            genres_display = ', '.join(genres_list)\n",
    "        else:\n",
    "            genres_display = \"Unknown\"\n",
    "            \n",
    "        print(f\"   Genres: {genres_display}\")\n",
    "        print(f\"   Runtime: {row['runtime']} mins\")\n",
    "        print()\n",
    "\n",
    "\n",
    "def main():\n",
    "#     # ------------------------------------------------\n",
    "#     # Load data\n",
    "#     # ------------------------------------------------\n",
    "#     load_dotenv()\n",
    "    repo = MovieRepository()\n",
    "    repo.load()\n",
    "\n",
    "\n",
    "\n",
    "    # engine.recommend(user_profile)\n",
    "\n",
    "    # ------------------------------------------------\n",
    "    # Load embedding model\n",
    "    # ------------------------------------------------\n",
    "    embedder = EmbeddingModel()\n",
    "\n",
    "    re_ranker = ReRankerModel()\n",
    "\n",
    "    # ------------------------------------------------\n",
    "    # Load FAISS index + mapping\n",
    "    # ------------------------------------------------\n",
    "    builder = IndexBuilder(repo, embedder)\n",
    "    faiss_index, mapping = builder.load_index()\n",
    "\n",
    "    # ------------------------------------------------\n",
    "    # Initialize core services\n",
    "    # ------------------------------------------------\n",
    "\n",
    "\n",
    "\n",
    "    service = ChatbotService()\n",
    "\n",
    "    result =service.run_chatbot()\n",
    "\n",
    "    # print(\"Conversation State:\", vars(result))\n",
    "\n",
    "\n",
    "    recommender = RecommendationEngine(\n",
    "        repository=repo,\n",
    "        embedding_model=embedder,\n",
    "        faiss_index=faiss_index,\n",
    "        index_to_movie_id=mapping,\n",
    "        reranker =re_ranker\n",
    "    )\n",
    "     \n",
    "\n",
    "    user_profile = get_useful_info(result)\n",
    "\n",
    "    # user_profile = {'query_text': 'love destiny power mythology good vs evil epic magical saga', 'genres': ['comedy', 'action', 'adventure'], 'language': None, 'runtime': None}\n",
    "\n",
    "    # user_profile = get_useful_info(result)\n",
    "    print(\"User Profile for Recommendations:\", user_profile)\n",
    "    recommended_df = recommender.recommend(user_profile)\n",
    "    print_recommendations(recommended_df)\n",
    "\n",
    "\n",
    " \n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10f7751b",
   "metadata": {},
   "source": [
    "#### Evaluation and Analysis:\n",
    "This system does not use a single accuracy metric like traditional ML models. Instead, it uses a ranking-based scoring approach, where each movie is given a relevance score and then ordered from most relevant to least relevant for a given query. The goal is not to predict a label, but to rank the best movies at the top.\n",
    "\n",
    "Types of scores used in the pipeline\n",
    "#### 1.\tSemantic similarity score (embedding score)\n",
    "The user query and each movie‚Äôs text (plot + themes) are converted into vector embeddings. A similarity score is computed using vector search (FAISS). This score measures how semantically close the movie description is to the query. This step is fast and helps retrieve relevant candidates, but it is approximate.\n",
    "#### 2.\tRe-ranker score (cross-encoder score)\n",
    "For the shortlisted candidates, a cross-encoder model scores how well each movie actually matches the query when both texts are read together. This score focuses on intent, tone, and narrative alignment, and is used to reorder results for better relevance.\n",
    "#### 3.\tFinal ranking score (combined score)\n",
    "The final score is a weighted combination of the semantic similarity score, the re-ranker score, and small optional boosts (such as genre preference or popularity). Movies with the highest final score are returned to the user.\n",
    "\n",
    "The model is evaluated using qualitative relevance checks, not numeric accuracy. \n",
    "We check whether:\n",
    " *\tthe top results match the user‚Äôs mood or genres prefered\n",
    " * incorrect genre or tone matches are pushed lower\n",
    " * \tknown reference movies (e.g., Enola Holmes, Mean Girls, Oppenheimer) appear near the top for relevant queries\n",
    "This approach reflects real-world recommender systems, where ranking quality and user relevance matter more than a single accuracy number\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d60f7745",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "99be08d1",
   "metadata": {},
   "source": [
    "#### Ethical Considerations & Responsible AI\n",
    "\n",
    "#### Bias in Data representation:\n",
    "The dataset used for this project is currently limited to 12k and extracted from tmdb dataset which might over represent English language movies, which can bias recommendations toward widely known titles and under-represent regional, independent, or niche cinema.\n",
    "\n",
    "#### Fairness in Recommendations\n",
    "Soft boosting for genres, language, and popularity is carefully tuned to avoid disproportionately favoring highly popular movies, helping ensure lesser known films still surface when they semantically match user preferences.\n",
    "\n",
    "#### Limitations of Mood Interpretation\n",
    "Mood and intent are inferred from natural language inputs and may be ambiguous or context-dependent. The system avoids making sensitive assumptions and uses mood signals only to guide content recommendations, not to profile users.\n",
    "\n",
    "#### Transparency and Explainability\n",
    "Recommendation logic is designed to be interpretable, combining semantic similarity with explicit preference boosts, making it possible to explain why certain movies were recommended.\n",
    "\n",
    "#### Responsible Use of LLMs\n",
    "LLMs are used strictly for interpreting user input and generating conversational responses, not for decision-making that affects users in high-risk domains, ensuring safe and appropriate usage.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9ebafdd",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "181cbe1e",
   "metadata": {},
   "source": [
    "### Summary and Furthere Enhancements\n",
    "\n",
    "This project successfully demonstrates an end-to-end AI-powered movie recommendation system that combines data engineering, semantic search, and LLM-based interaction. By leveraging vector embeddings, FAISS indexing, and preference-based ranking, the system is able to generate relevant and personalized movie recommendations from a dataset of approximately 13,000 movies. The conversational flow enables the assistant to understand user mood and preferences in natural language, resulting in recommendations that are both contextually relevant and efficient to retrieve.\n",
    "\n",
    "Future enhancements could include incorporating real user feedback signals such as clicks or ratings to enable learning-to-rank and more robust evaluation metrics. The system can be extended with larger and more diverse datasets to reduce popularity and language bias. Additional improvements may include fine-tuning embedding models on movie-specific data, introducing session-level memory for better personalization, and expanding the assistant to support other domains such as TV shows or personalized content discovery platforms."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac4ea2a1",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

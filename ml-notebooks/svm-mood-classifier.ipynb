{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cf60e9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sentence-transformers\n",
      "  Using cached sentence_transformers-5.1.2-py3-none-any.whl.metadata (16 kB)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\vindhya lingareddy\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (1.7.2)\n",
      "Requirement already satisfied: pandas in c:\\users\\vindhya lingareddy\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (2.3.3)\n",
      "Collecting sklearn\n",
      "  Downloading sklearn-0.0.post12.tar.gz (2.6 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'error'\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  × Getting requirements to build wheel did not run successfully.\n",
      "  │ exit code: 1\n",
      "  ╰─> [15 lines of output]\n",
      "      The 'sklearn' PyPI package is deprecated, use 'scikit-learn'\n",
      "      rather than 'sklearn' for pip commands.\n",
      "      \n",
      "      Here is how to fix this error in the main use cases:\n",
      "      - use 'pip install scikit-learn' rather than 'pip install sklearn'\n",
      "      - replace 'sklearn' by 'scikit-learn' in your pip requirements files\n",
      "        (requirements.txt, setup.py, setup.cfg, Pipfile, etc ...)\n",
      "      - if the 'sklearn' package is used by one of your dependencies,\n",
      "        it would be great if you take some time to track which package uses\n",
      "        'sklearn' instead of 'scikit-learn' and report it to their issue tracker\n",
      "      - as a last resort, set the environment variable\n",
      "        SKLEARN_ALLOW_DEPRECATED_SKLEARN_PACKAGE_INSTALL=True to avoid this error\n",
      "      \n",
      "      More information is available at\n",
      "      https://github.com/scikit-learn/sklearn-pypi-package\n",
      "      [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
      "error: subprocess-exited-with-error\n",
      "\n",
      "× Getting requirements to build wheel did not run successfully.\n",
      "│ exit code: 1\n",
      "╰─> See above for output.\n",
      "\n",
      "note: This error originates from a subprocess, and is likely not a problem with pip.\n"
     ]
    }
   ],
   "source": [
    "#%pip install sentence-transformers scikit-learn pandas sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cf455533",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Vindhya Lingareddy\\OneDrive\\Desktop\\movie-recommendation-system\\.venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Loaded:\n",
      "                                                text  label\n",
      "0                            i didnt feel humiliated      0\n",
      "1  i can go from feeling so hopeless to so damned...      0\n",
      "2   im grabbing a minute to post i feel greedy wrong      3\n",
      "3  i am ever feeling nostalgic about the fireplac...      2\n",
      "4                               i am feeling grouchy      3\n",
      "\n",
      "Loading SentenceTransformer model...\n",
      "Encoding text into embeddings...\n",
      "Embedding shape: (12800, 384)\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     sadness       0.69      0.78      0.74       933\n",
      "         joy       0.71      0.82      0.76      1072\n",
      "        love       0.58      0.34      0.43       261\n",
      "       anger       0.68      0.60      0.64       432\n",
      "        fear       0.66      0.55      0.60       387\n",
      "    surprise       0.73      0.29      0.41       115\n",
      "\n",
      "    accuracy                           0.69      3200\n",
      "   macro avg       0.68      0.56      0.60      3200\n",
      "weighted avg       0.68      0.69      0.68      3200\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[730 101  18  54  29   1]\n",
      " [106 883  25  20  32   6]\n",
      " [ 37 120  90   8   6   0]\n",
      " [ 91  49   8 258  26   0]\n",
      " [ 66  59  10  35 212   5]\n",
      " [ 22  38   4   2  16  33]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "\n",
    "# 1. Load the  dataset (text + label)\n",
    "\n",
    "df = pd.read_csv(\"datasets/mood-data.csv\")  \n",
    "df = df[['text', 'label']] \n",
    "\n",
    "\n",
    "print(\"Dataset Loaded:\")\n",
    "print(df.head())\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 2. Convert labels to integers \n",
    "# ---------------------------------------------------------\n",
    "\n",
    "# If labels already 0–4, no need to encode, but let's be safe:\n",
    "label_encoder = LabelEncoder()\n",
    "df['label'] = label_encoder.fit_transform(df['label'])\n",
    "\n",
    "# Map label IDs to emotion names\n",
    "label_names = {0: \"sadness\", 1: \"joy\", 2: \"love\", 3: \"anger\", 4: \"fear\", 5:\"surprise\"}\n",
    "\n",
    "df['label_name'] = df['label'].map(label_names)\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 3. Train-test split\n",
    "# ---------------------------------------------------------\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df['text'].values,\n",
    "    df['label'].values,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=df['label'].values\n",
    ")\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 4. Generate sentence embeddings\n",
    "# ---------------------------------------------------------\n",
    "\n",
    "print(\"\\nLoading SentenceTransformer model...\")\n",
    "embedder = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "print(\"Encoding text into embeddings...\")\n",
    "X_train_emb = embedder.encode(X_train, batch_size=32, convert_to_numpy=True)\n",
    "X_test_emb = embedder.encode(X_test, batch_size=32, convert_to_numpy=True)\n",
    "\n",
    "print(\"Embedding shape:\", X_train_emb.shape)\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 5. Train SVM classifier\n",
    "# ---------------------------------------------------------\n",
    "\n",
    "svm_model = SVC(kernel='linear', probability=True)\n",
    "svm_model.fit(X_train_emb, y_train)\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 6. Predictions\n",
    "# ---------------------------------------------------------\n",
    "\n",
    "y_pred = svm_model.predict(X_test_emb)\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 7. Evaluation\n",
    "# ---------------------------------------------------------\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred, target_names=[label_names[i] for i in sorted(label_names.keys())]))\n",
    "\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
